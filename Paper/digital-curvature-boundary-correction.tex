% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx,subfig}
\usepackage{amstext,amsmath,amssymb,bm,bbm,mathtools}

\newtheorem{ddef}{Definition}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Digital Curvature Boundary Correction\thanks{This  work has  been  partly  funded by CoMeDiC ANR-15-CE40-0006 research grant.}}

\author{Daniel Antunes\inst{1}
Jacques-Olivier Lachaud\inst{1}
Hugues Talbot\inst{2}}
%
\authorrunning{D. Antunes et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Laboratoire de Mathematiques (LAMA), Universite Savoie Mont Blanc, Chambéry, France
\email{daniel.martins-antunes, jacques-olivier.lachaud@univ-savoie.fr} \and
CentraleSupelec Université Paris-Saclay\\
\email{hugues.talbot@centralesupelec.fr}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Recent works indicate the potential of curvature as a regularizer in image segmentation, in particular for the class of thin and elongated objects, ubiquitous in medical imagery, in which length regularization performs badly. Howerver, state-of-art techniques make use of a coarse approximation of curvature  limiting its practical applications. We argue that curvature must be computed using a multigrid convergent estimator, instead. As an illustration, we propose a two-stage method based on the minimization of a squared curvature energy that enhances the output quality of grab-cut image segmentation.
 
\keywords{Multigrid convergence  \and Digital estimator \and Curvature \and Optimization.}
\end{abstract}
%
%
%

\section{Introduction}
Geometric quantities are particularly useful as regularizers, specially when object geometry is known a priori. Length is a general purpose regularizer and the literature is vast on models that make use of it (\cite{casseles97},\cite{appleton05}). However, length is not suitable to segmentation of thin and elongated objects, as it is propense to return oversegmented solutions. Such drawback can be overcomed by injecting curvature regularization \cite{zehiry10}.
				
One of the first successful uses of curvature in image processing is the inpainting algorithm described in \cite{masnou98}. The author evaluates the elastica energy along the level lines of a simply-connected image to reconstruct its occluded parts. The level lines property of non-intersection allows the construction of an efficient dynamic programming algorithm. Nonetheless, it is still a challenging task to inject curvature in the context of image segmentation. 

The state-of-art methods are difficult to optimize and  not practical \cite{schoenemann09},\cite{nieuwenhuis14}. Such approaches make use of a coarse and not convergent approximation of curvature, which is the cause of its long running times. 

In this work, we investigate the use of the more appropriated multigrid convergent estimators for curvature and its application as boundary regularizer. We propose a method that illustrates its effectiveness and discuss its potential to be applied in a complete segmentation model. 


\section{Multigrid Convergent Estimators}



A digital image is the result of some quantization process (e.g. Gauss digitization) over an object $X$ residing in some continuous space of dimension $d$. Such process is parameterized by a scale parameter $h>0$ and generates the object $D_h(X) \subset h \cdot \mathbb{Z}^d$, the digitization of $X$ in a grid space of size $h$. 


Because we have a quantization (instead of sampling) process, the same digital object can be the digitization of infinitely many others. Hence, it is not adequate the use of sample-based approximations to estimate geometric features. We can only state the trivial assertion that a refined grid will lead to improved results, but any word on the convergence speed can be said. Such approximations risks to be unpractical for certain classes of objects. Multigrid convergence is the tool to evaluate measures on digital objects without any assumption on the digital data. 

A digital estimator $\hat{u}$ defines  the reciprocal of a geometrical quantity $u$ of $X \subset \mathbb{R^d}$ (such as tangent or curvature) in its digitization $D_h(X)$. The quality of a digital estimator can be evaluated by proving the estimator is \textit{multigrid convergent}. 
	
	\begin{ddef}[Multigrid convergence for local geometric quantites]
		A local discrete geometric estimator $\hat{u}$ of some geometric quantity $u$ is multigrid convergent for the family $\mathbb{X}$ if and only if, for any $X \in \mathbb{X}$, there exists a grid step $h_X>0$ such that the estimate $\hat{u}(D_h(X),\hat{x},h)$ is defined for all $\hat{x} \in \partial_hX$ with $ 0 < h < h_X$, and for any $x \in \partial X$,
		
		\begin{equation}
			\forall \hat{x} \in  \partial_hX \text{ with } \norm{ \hat{x} - x }_{\infty} \leq h, \norm{ \hat{u}(D_h(X),\hat{x},h) - u(X,x)} \leq \tau_{X,x}(h),			
		\end{equation}
		
		where $\tau_{X,x}:\mathbb{R}^{+}\setminus\{0\} \rightarrow \mathbb{R}^{+}$ has null limit at $0$. This function defines the speed of convergence of $\hat{u}$ towards $u$ at point $x$ of $X$. The convergence is uniform for $X$ when every $\tau_{X,x}$ is bounded from above by a function $\tau_X$ independent of $x \in \partial X$ with null limit at $0$.
	\end{ddef}
	
	
	For a global geometric quantity (e.g. volume), the definition remains the same, except that the mapping between $\partial X$ and $\partial_h X$ is no longer necessary.
	
In the next section we describe two estimators that will be important for the remaining of this paper.

\subsection{Tangent and Length Estimators}
We represent a curve as a sequence of pointels (zero dimensional elements of the digital grid. Its respective higher dimensional counterparts are called linels and pixels). Sequence indexes are recovered by function $i_C(\cdot)$. The curve segment $C_{p,q}$ between pointels $p,q$ is a digital straight segment (DSS) if $C_{p,q}$ is a standard line.


\begin{ddef}[Standard line] 
The set of points
$(x, y)$ of the digital plane verifying $\mu \leq ax -by \leq \abs{a} + \abs{b}$ , with $a,b$ and $\mu$
integer numbers, is called the standard line
with slope $a/b$ and shift $\mu$.
\end{ddef}

The $\lambda$-MST estimates the tangent of some curve $C$ at some pointel $p$ as a ponderated sum over the set of maximal digital straight segments of $C$ containing $p$.



The curve $C$ can be covered by its set of maximal DSS $\mathcal{S}$. Hence, every pointel belongs to at least one maximal DSS. In fact, a pointel $p$ can be present in two or more elements of $\mathcal{S}$. We denote the pencil of $p$ by $\mathcal{P}(p) \subset \mathcal{S}$ as the set of maximal DSS which passes through $p$. We are now ready to characterize the eccentricity between a pointel $p$ and its pencil elements $M \in \mathcal{P}(p)$.

\begin{align*}
	e_p(M) = \frac{\abs{i_M(p) - i_M(q)} }{\abs{M}}. 
\end{align*}

The eccentricity is used to define the weight function $\lambda:[0,1]\rightarrow \mathbb{R}^+$. A good choice would be bell-shaped functions as the $C^2$ function $64(-x^6 + 3x^5 - 3x^4 + x^3)$ or the $C^{\infty}$ function $exp(4 - \frac{1}{x} - \frac{1}{1-x}).$ as noted by \cite{lachaud07}.

\begin{ddef}[$\lambda$-MST] 
The $\lambda$-maximal segment tangent direction at pointel $p$ is then defined as the weighted combination of the directions of the surrounding maximal segments:
\end{ddef}

\begin{align*}
	\hat{\theta}(p) = \frac{ \sum_{M \in \mathcal{P}}{\lambda( e_p(M) )}\theta_M }{\sum_{M \in \mathcal{P}}{\lambda( e_p(M) )}}.
\end{align*}

The $\lambda$-MST is linearly convergent with average rate $O(h^{\frac{1}{3}})$ for the class of convex shapes with bounded curvature and finite number of inflexion points. A multigrid convergent estimator for length with equal convergence properties can be derived by integration.

\begin{align*}
	\hat{s} = h \cdot \sum_{l \in \mathcal{L}(C)}{\hat{\theta}(l) \cdot or(l)},
\end{align*}

where $\mathcal{L}(C)$ is the linel set of $C$ and $or(\cdot)$ the direction of a linel.


\subsection{Integral Invariant Curvature Estimator}
Generally, an invariant $\sigma$ is a real-valued function from some space $\Omega$ which value is unnafected by action of some group $\mathfrak{G}$ on the elements of the domain
		
		\begin{align*}
			x \in \Omega, g \in \mathfrak{G}, \sigma(x) = v \longleftrightarrow \sigma(g \cdot x ) = v
		\end{align*}
		
		Perimeter and curvature are examples of invariants for shapes on $\mathbb{R}^2$ with respect to the euclidean group (rigid transformations). Definition of integral area invariant and its one-to-one correspondence with curvature is proven in \cite{manay04}.


\begin{ddef}[Integral area invariant]
	Let $X \in \mathbb{R}^2$ and $B_r(p)$ the ball of radius $r$ centered at point $p$. Further, let $\mathbbm{1}_X(\cdot)$ be the characteristic function of $X$. The integral area invariant $\alpha_{X,r}(\cdot)$ is defined as
	
	\begin{align*}
		\forall p \in \partial X, \quad \sigma_{X,r}(p) = \int_{B_r(p)}{ \mathbbm{1}_X(x) dx}.
	\end{align*}
\end{ddef}


	The value $\sigma_{X,r}(p)$ is the intersection area of ball $B_r(p)$ with shape $X$. By locally approximating the shape at point $p \in X$, one can rewrite the intersection area $\sigma_{X,r}(p)$ in the form of the Taylor expansion \cite{pottman09}
	
		\begin{align*}
			\sigma_{X,r}(p) = \frac{\pi}{2}r^2 - \frac{\kappa(X,x)}{3}r^3 + O(r^4).
		\end{align*}
		
	The curvature of $X$ at point $p$ can be approximated at arbitrarly precision as the radius $r$ approaches to zero by
	
	\begin{align}
		\tilde{\kappa}(p) \coloneqq \frac{3}{r^3}\left( \frac{\pi r^2}{2} - \sigma_{X,r}(p) \right),
		\label{eq:curvature_approximation}
	\end{align}
	
	Such approximation is convenient as one can simply devise a multigrid convergent estimator for area.

	\begin{ddef}	
		Given a digital shape $D \subset \frac{1}{h} \cdot \mathbb{Z}^2$, a multigrid convergent estimator for area $\widehat{Area}(D,h)$ is defined as	
		
		\begin{align}
			\widehat{Area}(D,h) \coloneqq h^2\text{Card}\left( D \right).			
			\label{eq:digital_estimator_area}
		\end{align}

	\end{ddef}
	
	In \cite{coeurjolly13}, the authors use the approximation\eqref{eq:curvature_approximation} and digital estimator \eqref{eq:digital_estimator_area} to define a multigrid convergent estimator for curvature.

	\begin{ddef}[Integral Invariant Curvature Estimator]
		Let $D \in \frac{1}{h} \cdot \mathbb{Z}^2$ a digital shape. The integral invariant curvature estimator is defined as
		
		\begin{align*}
			\hat{\kappa}_{II} \coloneqq \frac{3}{r^3} \left( \frac{\pi r^2}{2} - \widehat{Area} \left( B_{r/h} ( \frac{1}{h} \cdot x ) \cap D, h \right) \right).
		\end{align*}
	\end{ddef}
	

	The estimator is robust to noise and can be extended to estimate the mean curvature of three dimensional shapes.
	

\section{Digital Boundary Correction}

In this section we describe our method. We aim to enhance the quality of general segmentation methods, which tends to produce regions with artificial contours. A high quality segmentation produces an image which looks natural and is visual appealing. 

We briefly discuss an ideal global optimization model and discuss its practicity before detailing our local approach.


\subsection{Ideal Global Optimization Model}

We evaluate the quality of a segmentation by evaluating the elastica energy over the contour of the segmented region $X$. In continuous terms, the elastica energy is defined as:

\begin{align*}
	E(X) = \int_{\partial X}{(\alpha + \beta \kappa^2) ds}.
\end{align*}

We are going to use the digital version of the energy, using multigrid convergent estimators. The energy, in this case, is also multigrid convergent.

\begin{align}
	\hat{E}(X) = \sum_{x \in \partial D_h(X)}{ \hat{s}(x)\left(\; \alpha + \beta \hat{\kappa}_{II}^2(x) \; \right)}.  
	\label{eq:digital-energy}
\end{align}

A global method for energy \eqref{eq:digital-energy} necessarily need to restrict the optimization domain to consistent regions. We cannot proper estimate length and curvature along anything different from a boundary, and in our case, a closed boundary. Let $I$ be the image domain. Denote by $\mathcal{T}$ the family of subsets of $I$ satisfying the property

\begin{align*}
	X \in \mathcal{T} \implies X \subset I \text{ and } 4B(\partial X),
\end{align*} 

where $4B(\cdot)$ is the $4$-connected closed boundary predicate. 


The global optimization problem can be stated as:

\begin{align*}
	\min_{X \in \mathcal{T}}{\sum_{x \in \partial D_h(X)}{ \hat{s}(x)\left(\; \alpha + \beta \hat{\kappa}^2(x) \; \right)}.}
\end{align*}

In its integer linear programming model \cite{schoenemann09}, Schoenemann restricts the optimization domain by enforcing a set of consistent constraints. The model is unpractical if one wishes to obtain reasonable approximations of the squared curvature. We expect to 

\subsection{Our Local Optimization Model}


Instead of restricting the optimization domain, we assume a warm start. As input $X$, our method expects the segmented region given by some general segmentation framework as GrabCut \cite{rother04}. Next, our method will improve its boundary with respect to energy \eqref{eq:digital-energy}. We proceed by describing the two main routines correct and expand as illustrated in \ref{alg:boundary-correction}.


\begin{figure}
\begin{tt}
boundaryCorrection(I,it,a,b)\\
\hspace{2pt} R = grabcut(I)\\
\vspace{2pt}

\hspace{2pt} for i=0 until i=it\\
\hspace{4pt} R=correct(R,a,b)\\
\vspace{2pt}

\hspace{2pt} for i=0 until i=it\\
\hspace{4pt} R=expand(R,a,b)\\
\vspace{2pt}

\hspace{2pt} return R;

\end{tt}
   \caption{Boundary correction pseudo-code.}
      \label{alg:boundary-correction}
\end{figure}

\subsubsection{Correct Routine}

Given some digital region $R$, we define its $4$-connected boundary as $\partial R$ and its trust set as $T = R \bigtriangleup \partial R$. Further, define $Y=\partial R$ as the optimization variables set. Consider the squared curvature part of energy \eqref{eq:digital-energy} evaluated at some point $p \in \partial R$.


		\begin{align}
			E_{\kappa}(p) = \hat{\kappa}_{II}^2(p)	=	\left( \; \frac{3}{r^3}\left( \frac{\pi r^2}{2} - \sigma_{R,r}(p) \right) \; \right)^2.\label{eq:correction-opt-energy-not-expanded}
		\end{align}

	
	Further, let $Y_{p} \subset Y$ to be the subset of optimization variables intersecting with $B_r(p)$. The subset $T_p$ is defined analogously. The factor $\sigma_{R,r}$ can be decomposed in two other terms representing the contribution of points in the fidelity and optimization set.
	
	\begin{align*}
		\sigma_{R,r}(p) = |T_{p}| + \sum_{y_i \in Y_p}{y_i},
	\end{align*}
	
	Let $Q \coloneqq \frac{\pi r^2}{2}$. Reorganizing terms in \eqref{eq:correction-opt-energy-not-expanded} and ignoring the constants 
	
	\begin{align*}
		E_{\kappa}(p) &= \left( \; \sum_{y_i \in Y_{p}}{y_i} \; \right) ^2 -2 \cdot Q\cdot \sum_{y_i \in Y_{p}}{y_i} + 2 |T_p| \cdot \sum_{ y_i \in Y_{p} }{y_i} \\[1em]
		&= \sum_{y_i \in Y_{p}}{x_i^2} + 2 \cdot \sum_{ \substack{ i<j \\ y_i,y_j \in Y_{p}  } }{y_iy_j} \quad - 2 (Q-|F_p|)\cdot \sum_{y_i \in Y_{p}}{y_i}
	\end{align*}
	
	Which can be further simplified by using the binary character of the variables.
	
	\begin{align*}
		E_{\kappa}(p) =\sum_{ \substack{ i<j \\ y_i,y_j \in Y_{p}  } }{y_iy_j} \quad  - \;(Q-|T_p|-1/2)\cdot \sum_{y_i \in Y_{p}}{y_i}
	\end{align*}	
	
	The correction routine proceeds by solving
	
	\begin{align}
		\min_{Y} \sum_{p \in \partial R}E_{\kappa}(p)
		\label{eq:optimization_problem_no_conn}
	\end{align}
	
	Executing the correction routine on a digital square will produce a solution similar to figure \ref{fig:naive_solution}. The correction routine identifies regions of high curvature in the optimization region, namely, regions in which some modification is necessary. 
	
	
	Recall that the working principle of the integral invariant estimator consists to account a lack or an abundance of region pixels in the interior of the estimating ball. Therefore, labeled-one regions are zones with lack of pixels, and assuming that the boundary remains the same except on those regions, we should remove those pixels in order to pull the estimating ball towards the center of our object, thus reducing the lackability of pixels in those zones.


	\begin{figure}[!ht]
		\center
		\subfloat[\label{fig:naive_solution}]{%
		\includegraphics[scale=2.0]{images/qbo_1D_naive_solution_noneigh.png}
		}%
		\hspace{80pt}
		\subfloat[\label{fig:naive_solution_updated}]{%
		\includegraphics[scale=2.0]{images/qbo_1D_naive_solution_noneigh_updated.png}}
		\caption{White zones in figure (a) are the labeled-one pixels by the optimization process. These zones express a lack of pixels state wrt to the II estimator; Figure (b) illustrates the output of the correction routine. Zones with lack of pixels are removed.   }				
	\end{figure}
	
	
	Our energy is non-submodular and optimizing it is a NP-hard problem, which restrict ourselves to heuristics and approximation algorithms. The QPBO method \cite{kolmogorov07} transforms the original problem in a max-flow/min-cut problem and returns a full optimal labeling for submodular energies. For non-submodular energies the method is guaranteed to return a partial labeling with the property that the set of labeled variables is part of an optimal solution. 
	
	However, QPBO left many pixels unlabeled. [[[Elaborate on the use of the probe version, QPBOP \cite{rother07}]]]. Nonetheless, we found that by a slightly modification in the optimization function we can recover high-quality solutions with QPBO. The modification consists into the application of the estimating ball in several contour levels, and not only in the boundary of the input region. The motivation is simple: The lack of pixel state is carried over the succesive levels accordingly with its lack intensity. Such extra information makes the work easier for the QPBO method.
	
\subsubsection{Expand}
The same rational from correction routine is applied in the expasion routine. However, the optimization set in this case will be the boundary of the dilation of $R$ by the square of side one, denoted $\partial R^+$. Additionaly, a data attachment term $g(\cdot)$ is included. In summary,

	\begin{align}
		\min_{Y} \sum_{p \in \partial R^+}E_{\kappa}(p) + g(p)
		\label{eq:optimization_problem_no_conn}
	\end{align}
	
	

\section{Results}

\section{Conclusion}

Future work: Evaluate the effevtiveness of $\kappa_{II}$ in a complete segmentation model. A possible direction is to enforce some constraints in order to limit the optimization domain to consistent solutions, similarly to the constraints of Schoenemann. We expect to recover better results in lower running time.


%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{bibliography}

\end{document}
